---
title: "Practical 5: Visualisation"
format: html
---

# In this practical

In this practical you will:

1. Create visualisations in `R` using the `plot()` function in the `base` package.
2. Try using `ggplot2` to make more advanced plots.
3. Explore statistical visualisations techniques

# 1. Module imports

For this practical we first need to load any packages we will use.

The `plot()` is part of the `base` package that is automatically loaded whenever you start `R`. The `graphics` package also has some plotting functions and it also is loaded automatically.

We'll also be using a new library, `ggplot2`, which allows us to do advanced plotting more easily than use the `base` plotting functions.

```{r}
library(ggplot2)
```

# 2. Importing, cleaning, and first visualisations

The first steps in trying to extract insights out of data is to import it and clean it. 

For this practical, we'll be using data on the finish times of athletes in various foot races frp, across the world.

```{r}
run_data_path = "../data/run17.csv"
run_df = read.csv(run_data_path)
run_df
```

## Data exploration

The first step is to get an intuitive understanding of what our datasets contains. Explore the data using the following functions:

- `str()`
- `summary()`
- `unique(df$ColumnName)` for a given column named `ColumnName`

```{r}
# str() display the structure of the data frame
str(run_df)
```

```{r}
# Summary - check to see if any columns have missing values (NA's)
  summary(run_df)

```

```{r}
# Unique City
  unique(run_df$city)

```

```{r}
# Unique values of other categorical variables
  unique(run_df$sex)  
  unique(run_df$event)
  
```

## Preparing a visualisation

A good visualisation includes several elements:

- Well labelled axes that includes units.
- Clearly presented information 

If you are ever unsure of how to use a method, `R`'s built-in help documentation is your friend. You can find the documentation for any function by running `help(FunctionName)`.

NB: the `!` used below is the boolean NOT operator which inverts TRUE to FALSE and vice versa.

### Getting an idea of the overall breakdown

```{r}
# Plot `net_sec` against `age` coloured by `sex`
# Hint: use the plot() function from the previous practical

long_run_df = run_df[run_df$event == "10 Mile",]
mask = long_run_df$sex == "M"
male_df = long_run_df[mask,]
female_df = long_run_df[!mask,]

plot(x = male_df$age, 
     y = male_df$net_sec, 
     col = rgb(red = 0, green = 0, blue = 1, alpha = 0.1),
     pch = 20, # use filled circles as plot markers
     main = "Race Finishing Times (10 miles)",
     xlab = "Age (years)",
     ylab = "Finish time (s)")
points(x = female_df$age, 
       y = female_df$net_sec, 
       col = rgb(red = 1, green = 0, blue = 0, alpha = 0.1),
       pch = 20)
legend("bottomright", legend = c("Male", "Female"), pch = 20, col = c("blue", "red"))

```

# `ggplot2` - Advanced visualisation

`ggplot2` is another `R` package with a different approach to building plots in `R`.

According to its documentation found at <https://ggplot2.tidyverse.org/>:

> `ggplot2` is a system for declaratively creating graphics, based on [The Grammar of Graphics](https://link.springer.com/book/10.1007/0-387-28695-0). You provide the data, tell `ggplot2` how to map variables to aesthetics, what graphical primitives to use, and it takes care of the details.

## Distributional understanding

Before doing statistical analysis, you need to understand the underlying data and how it is distributed.

`ggplot2` makes a lot of this easier, less time consuming, and pretty by default.
We'll use `ggplot2`'s `geom_histogram()` function to plot a histogram.

seaborn.set_theme(style="ticks")
seaborn.displot(data=long_run_df, x="age", col="sex", kde=True)

plt.suptitle("Breakdown of runner age conditioned by sex")
plt.tight_layout()

‚ùì What relationships can you see in the plot above? Is there anything worth investigating?
Seaborn theme

Seaborn allows us to update all future figures by setting a theme, without needing to pass in arguments.

Try reproducing the above plot but with the pre-made theme style called darkgrid

seaborn.set_theme(style="darkgrid")

seaborn.displot(data=long_run_df, x="age", col="sex", kde=True)

plt.suptitle("Breakdown of runner age conditioned by sex")
plt.tight_layout()

Scatter Matrix for Data exploration

A common technique for exploring relationships is called a scatter matrix, which scatters each variable against another. We can also assign colours based on categorcal attributes, such as sex

# note that darkgrid theme set above is still active
seaborn.pairplot(long_run_df, hue="sex", plot_kws={"alpha": 0.1}, palette={"M": "blue", "F": "red"})

‚ùì Questions

    What trends can you see in the data above?
    Discuss what other visualisations might you make (using matplotlib or seaborn) to explore relationships in the data? How might you condition or display the data beforehand?

Make another two more plots based on your discussion, possibly creating a new, conditioned dataframe to plot

# Vis 1

# Vis 2

Belt wear

Let's use the belt wear data from the lecture to explore what makes a good visualisation

    The thickness along an 1800mm long drive-belt is measured at various points ("X") on installation
    The thickness at these points is then re-measured at several other dates and noted in "Result" as a measurement in mm
    This data is stored in a spreadsheet

belt_wear_df = pd.read_csv("../data/belt.csv")
belt_wear_df

# Belt wear info, describe, etc

 

 

# Get date to correct type data
belt_wear_df["Test Date"] = pd.to_datetime(belt_wear_df["Test Date"])
# Create a "relative test date" column
belt_wear_df["Relative Test Date (days)"] = (
    belt_wear_df["Test Date"] - belt_wear_df["Test Date"].min()
).dt.days
belt_wear_df.info()

‚ùì Whats wrong with the below plot?

Run the below cell to produce a figure, and think about what may be wrong

seaborn.scatterplot(belt_wear_df, x="X", y="Result", hue="Test Date")

üèÜ Challenge: Create a better plot using the elements of visualisations shown in the lecture:

    Scale
    Conditioning
    Perception - Colour and length
    Transformations
    Context
    Smoothing and other large data considerations Not all of these may be applicable

Some hints and suggestions (click me):

    Make the plot bigger with plt.figure(figsize=(x,y)) (you will need to create the figure before plotting, otherwise a second figure is made and the first is unchanged)
    Create a "Relative Test Date (days)" column and colour by that, rather than an absolute date
    Use a colour scale (such as 'viridis') for the test dates , not random colours. See here
    Connect the lines for a given date
    Include a legend
    Use x and y axes labels that are easier to understand
        What actually are "X" and "Result"?
        Include units!
    Set the y-axes limits properly
    Create a good title with plt.suptitle (short for super title)

To do all of this, read the scatterplot documentation and find the correct methods.

Talk to your neighbours and see what they do!

# Make your plot better in this cell!
seaborn.scatterplot(belt_wear_df, x="X", y="Result", hue="Test Date")

Exploring complex relationships in Concrete data

Let's switch back to use a reliability dataset that while a little less clearcut, may be more relevant.

Let's do some exploratory data analysis to better understand it:

    Understand data information
    Understand data distributions
    Understand any particularly clear relationships with a scatterplot Matrix
    Improving Visualisations

conrete_path = "../data/concrete.csv"
concrete_df = pd.read_csv(conrete_path)
concrete_df

seaborn.displot documentation can be found here: https://seaborn.pydata.org/generated/seaborn.displot.html

# create a displot of concrete age
# seaborn.displot() of "Age"


# Esnure your axes are labeled and you have a plt.suptitle()

# tight layout helps in case of overlap issues
plt.tight_layout()

üñä Example analysis: does the amount of water play a role in compressive strength?

    Get an understanding of how your variables are distributed

# seaborn.displot() of "Water"


# Esnure your axes are labeled and you have a plt.suptitle()

# tight layout helps in case of overlap issues
plt.tight_layout()

    Come up with a way a way of conditioning data, e.g. resample water data into categorical bins. We can use pd.cut for this, by giving it bins based on the above plot.

pd.cut is somewhat similar to pd.resample, but will transform one column into categories based on the bins given

You could start by trying bins = [120, 160, 200, 240]

bins = []  # Fill me in!
# Adding a new column called "water_bin"
concrete_df["water_bin"] = pd.cut(x=concrete_df["Water"], bins=bins)
# Showing the new column we made
concrete_df["water_bin"]

    Visualise!

# Make a displot of "CompressiveStrength" with the `col` arugment` being our new data column: "water_bin"
seaborn.displot(data=concrete_df, x="fill me!", col="fill me!", kde=True)

plt.suptitle("Distribution of water used in concrete")
plt.tight_layout()

Did you gather any insights?

Would more bins make a difference?

Are there any other variables you might want to have a look into?
What next?

After making observations of the data finding possible correlations, what do you do next?

    Form a Hypothesis
    Test with an experiment
    Analysis Data
    Report Conclusion
    Repeat...

 

üèÜ Bonus: Chemical Data

Time permitting, perform similar analysis of the chemical data.

# import csv file from the ../data directory and save as a variable
# dataframe looking wierd? make sure to use header=1
pd.read_csv("../data/chemicalmanufacturingprocess.csv", header=1)

# info, describe, etc

Before going too far, note that there are 58 variables. Trying to correlate all these plots will results in

! This image is roughly 14000x14000 pixels and might take your jupyter notebook some time to produce and be hard to read.

Some general methods to deal with this:

    Make smart decisions about which factors to look at based on real world information and prior knowledge (cant do that here)
    Arbitrarily select some columns to process (better than not doing anything)
    Perform dimensionality reduction. e.g. Perform Principle Component Analysis (PCA) and only analyse the principle components with the most variance.
    Contact your data science team....

While we wont perform PCA here, for extra reading, see PCA from the scikitlearn package

# Select some columns to look at

# some basic plots of some single variables

# Some mutlivariate analysis

 

 

